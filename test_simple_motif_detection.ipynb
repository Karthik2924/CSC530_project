{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the simulation code\n",
    "import NBInclude\n",
    "import Random\n",
    "import StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the code from the l,d motif simulation notebook\n",
    "NBInclude.@nbinclude(\"simulate_ld_motif.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# set the seed\n",
    "# Random.seed!(100)\n",
    "# use tuple unpacking to get some test values\n",
    "# NumberOfSequences, LengthMotif, LengthSequences, Distance\n",
    "motif, motif_starts, motifs_implanted, sequences = GenerateTestData_ld(20, 5, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now implement the standard algorithm for motif detection from bioinformatics 2\n",
    "# given we known the length\n",
    "function FindMotifs(Sequences, MotifLength)\n",
    "    # code skeleton\n",
    "    background_rates = StatsBase.proportionmap(reduce(vcat, Sequences))\n",
    "    # pick a random sequence at random. scan along this sequences, and create a \"generator\"\n",
    "    \n",
    "    # here, we'll just start with the first one\n",
    "    starter = Sequences[1]\n",
    "    \n",
    "    # construct all the potential starting sequences, by moving along the sequence\n",
    "    potential_starts = Dict(k => @view(starter[k:(k + MotifLength - 1)]) for k in 1:(length(starter) - MotifLength + 1))\n",
    "    \n",
    "    # now construct a generator for each potential case\n",
    "    # that is a mixture of 75% background and 25% current position\n",
    "    # implement using a slow for loop\n",
    "    model_dict = Dict()\n",
    "    for (k, v) in pairs(potential_starts)\n",
    "        model_dict[k] = Dict()\n",
    "        for i in 1:length(v)\n",
    "            model_dict[k][i] = Dict(xk => xv/4 for (xk, xv) in pairs(background_rates))\n",
    "            model_dict[k][i][v[i]] += 0.75 \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # generate a 3 dimensional array\n",
    "    # which should contain the\n",
    "    #   model being scored in the first dimension\n",
    "    #   sequence being scored in the second dimension\n",
    "    #   and starting position in the last dimension\n",
    "    score_saver = zeros(Float64, length(starter) - MotifLength + 1, length(Sequences), length(starter) - MotifLength + 1)\n",
    "\n",
    "    # initialize a vector for the scores\n",
    "\n",
    "    # loop over each potential model\n",
    "    for model in 1:(length(starter) - MotifLength + 1)\n",
    "        this_model = model_dict[model]\n",
    "        # then loop over each sequence\n",
    "        for i_seq in 1:length(Sequences)\n",
    "            seq = Sequences[i_seq]\n",
    "            # collect the scores in a vector\n",
    "            # finally, loop over each starting position in that sequence\n",
    "            for j_seq in 1:(length(seq) - MotifLength + 1)\n",
    "                # grab the sequence that we are going to be scoring\n",
    "                seq_inner = seq[j_seq:(j_seq + MotifLength - 1)]\n",
    "                a = sum(map((i, j) -> log(this_model[i][j]), 1:MotifLength, seq_inner))\n",
    "                b = sum(map((i, j) -> log(background_rates[j]), 1:MotifLength, seq_inner))\n",
    "                score_saver[model, i_seq, j_seq] = 2 * (a - b)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # find the maximum score for each model x sequence\n",
    "    max_byseq = dropdims(maximum(score_saver, dims=3) , dims = 3)\n",
    "\n",
    "    # figure out which of these is the largest - that's the starting position\n",
    "    pos_in_starter = findmax(dropdims(sum(max_byseq, dims = 2), dims = 2))[2]\n",
    "    # now, slice the matrix so we can find the maximum in each of the other dimensions\n",
    "    guessed_pos = vec(mapslices(x -> findmax(x)[2], score_saver[pos_in_starter,:,:]; dims = 2))\n",
    "    \n",
    "    # now, run more iterations\n",
    "    # construct a new generator that is equal parts from each sequence\n",
    "    # that is a mixture of 5% background and the rest equally divided across the genes\n",
    "    # implement using a slow for loop\n",
    "    tentative_model = Dict()\n",
    "    for i in 1:MotifLength\n",
    "        tentative_model[i] = Dict(xk => xv/20 for (xk, xv) in pairs(background_rates))\n",
    "        # go through all of the sequences\n",
    "        for seq in 1:length(Sequences)\n",
    "            # figure out which base is at this position\n",
    "            this_char = Sequences[seq][guessed_pos[seq] + i - 1]\n",
    "            tentative_model[i][this_char] += 0.95/length(Sequences)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # now find the best position in each sequence based on this scoring method\n",
    "    score_saver = zeros(Float64, length(Sequences), length(starter) - MotifLength + 1)\n",
    "    \n",
    "    # rescore\n",
    "    for i_seq in 1:length(Sequences)\n",
    "        seq = Sequences[i_seq]\n",
    "        # collect the scores in a vector\n",
    "        # finally, loop over each starting position in that sequence\n",
    "        for j_seq in 1:(length(seq) - MotifLength + 1)\n",
    "            # grab the sequence that we are going to be scoring\n",
    "            seq_inner = seq[j_seq:(j_seq + MotifLength - 1)]\n",
    "            a = sum(map((i, j) -> log(tentative_model[i][j]), 1:MotifLength, seq_inner))\n",
    "            b = sum(map((i, j) -> log(background_rates[j]), 1:MotifLength, seq_inner))\n",
    "            score_saver[i_seq, j_seq] = 2 * (a - b)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # find the maximum in each row again\n",
    "    guessed_pos = vec(mapslices(x -> findmax(x)[2], score_saver, dims = 2)) \n",
    "    \n",
    "    # now, try updating the probabilities and checking one more time\n",
    "    return(guessed_pos)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FindMotifs(sequences, length(motif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "begin\n",
    "    n = 10\n",
    "    summer = zeros(n)\n",
    "    for i in 1:n\n",
    "        motif, motif_starts, motifs_implanted, sequences = GenerateTestData_ld(100, 14, 100, 2)\n",
    "        summer[i] = StatsBase.mean(FindMotifs(sequences, length(motif)) .== motif_starts)\n",
    "    end\n",
    "    println(summer)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
